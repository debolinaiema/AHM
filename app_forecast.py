# import pandas as pd
# import numpy as np
# import joblib
# import torch
# import torch.nn as nn
# import pickle
# from tensorflow.keras.models import model_from_json
# from sklearn.preprocessing import StandardScaler
# import warnings
# from datetime import timedelta
# import matplotlib.pyplot as plt
# warnings.filterwarnings("ignore")

# def load_trained_model(pickle_filename='trained_multivariate_model.pkl'):
#     """Load the trained Keras model and all its components from pickle file"""
#     try:
#         print(f"--- Loading model from '{pickle_filename}' ---")
#         with open(pickle_filename, 'rb') as f:
#             package = pickle.load(f)

#         model = model_from_json(package['model_architecture'])
#         model.set_weights(package['model_weights'])
#         model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

#         return {
#             'model': model,
#             'scaler_X': package['scaler_X'],
#             'scaler_y': package['scaler_y'],
#             'SEQUENCE_LENGTH': package['SEQUENCE_LENGTH'],
#             'n_features': package['n_features'],
#             'feature_names': package['feature_names']
#         }
#     except Exception as e:
#         print(f"‚ùå Error loading model: {e}")
#         return None
        
# class GRUBasedAutoencoder(nn.Module):
#     def __init__(self, seq_length=60, n_features=3, hidden_dim1=64, hidden_dim2=32):
#         super(GRUBasedAutoencoder, self).__init__()
#         self.seq_length = seq_length
#         self.n_features = n_features
#         self.hidden_dim1 = hidden_dim1
#         self.hidden_dim2 = hidden_dim2

#         self.gru1 = nn.GRU(input_size=n_features, hidden_size=hidden_dim1, batch_first=True)
#         self.dropout1 = nn.Dropout(0.2)
#         self.gru2 = nn.GRU(input_size=hidden_dim1, hidden_size=hidden_dim2, batch_first=True)
#         self.dropout2 = nn.Dropout(0.1)
#         self.decoder = nn.Sequential(
#             nn.Linear(hidden_dim2, 16),
#             nn.ReLU(),
#             nn.Linear(16, seq_length * n_features),
#             nn.Unflatten(1, (seq_length, n_features))
#         )

#     def forward(self, x):
#         out1, _ = self.gru1(x)
#         last_t1 = out1[:, -1, :]
#         last_t1 = self.dropout1(last_t1)
#         out2, _ = self.gru2(last_t1.unsqueeze(1))
#         last_t2 = out2.squeeze(1)
#         last_t2 = self.dropout2(last_t2)
#         decoded = self.decoder(last_t2)
#         return decoded

# def classify_data(classifier_path, df):
#     clf_bundle = joblib.load(classifier_path)
#     clf = clf_bundle['clf']
#     scaler = clf_bundle['scaler']
#     features = clf_bundle['features']

#     X = df[features].values
#     X_scaled = scaler.transform(X)
#     preds = clf.predict(X_scaled)
#     label = int(np.bincount(preds).argmax())
#     return "Phase 3 Motor" if label == 0 else "Gearbox Motor"

# def load_gru_model(model_path):
#     checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
#     model = GRUBasedAutoencoder(
#         seq_length=checkpoint['seq_length'],
#         n_features=checkpoint['n_features'],
#         hidden_dim1=checkpoint['hidden_dim1'],
#         hidden_dim2=checkpoint['hidden_dim2']
#     )
#     model.load_state_dict(checkpoint['model_state_dict'])
#     model.eval()
#     return model

# def forecast_vibration(csv_path, classifier_path, model_dir, forecast_model_path, forecast_time):
#     df = pd.read_csv(csv_path)
#     df['timestamp'] = pd.to_datetime(df['timestamp'])
#     df = df.sort_values('timestamp')

#     label = classify_data(classifier_path, df)
#     print(f"\nüîπ Classified Motor Type: {label}\n")

#     if "Phase 3" in label:
#         gru_model_path = f"{model_dir}/3phase.pt"
#         scaler_path = f"{model_dir}/3phase_scaler.pkl"
#     else:
#         gru_model_path = f"{model_dir}/gearbox.pt"
#         scaler_path = f"{model_dir}/gearbox_scaler.pkl"

#     model_auto = load_gru_model(gru_model_path)
#     scaler = joblib.load(scaler_path)

#     loaded_components = load_trained_model(forecast_model_path)
#     if loaded_components is None:
#         raise ValueError("Failed to load forecasting model.")
#     forecast_model = loaded_components['model']
#     SEQUENCE_LENGTH = loaded_components['SEQUENCE_LENGTH']
#     n_features = loaded_components['n_features']

#     vibrations = df[['vibration_x', 'vibration_y', 'vibration_z']].values.astype(np.float32)
#     scaled_vibes = scaler.transform(vibrations)

#     last_timestamp = df['timestamp'].iloc[-1]
#     time_diff = df['timestamp'].diff().median()
#     steps_per_hour = int(timedelta(hours=1) / time_diff)
#     if "hour" in forecast_time.lower():
#         total_steps = steps_per_hour * int(forecast_time.split()[0])
#     elif "day" in forecast_time.lower():
#         total_steps = steps_per_hour * 24 * int(forecast_time.split()[0])
#     else:
#         raise ValueError("Forecast time must include 'hours' or 'days'.")

#     print(f"‚è± Forecasting next {forecast_time} ({total_steps} steps)...")
#     input_data = scaled_vibes[-SEQUENCE_LENGTH:]
#     preds = []
#     np.random.seed(42)
#     recent_std = np.std(scaled_vibes[-SEQUENCE_LENGTH:], axis=0)
#     base_noise_level = 0.02 * np.mean(recent_std)
#     spike_prob = 0.15
#     spike_strength = 0.6 * np.mean(recent_std)

#     for step in range(total_steps):
#         input_seq = input_data[-SEQUENCE_LENGTH:].reshape(1, SEQUENCE_LENGTH, n_features)
#         pred_scaled = forecast_model.predict(input_seq, verbose=0)
#         noise = np.random.normal(0, base_noise_level, size=pred_scaled.shape)
#         spikes = np.random.binomial(1, spike_prob, size=pred_scaled.shape)
#         spike_magnitude = np.random.normal(0, spike_strength, size=pred_scaled.shape)
#         spike_noise = spikes * spike_magnitude
#         if np.random.rand() < 0.05:
#             burst = np.random.normal(0, 3 * spike_strength, size=pred_scaled.shape)
#             spike_noise += burst

#         pred_scaled_noisy = pred_scaled + noise + spike_noise
#         preds.append(pred_scaled_noisy.flatten())
#         input_data = np.vstack([input_data, pred_scaled_noisy.reshape(1, -1)])

#     preds_array = np.array(preds)
#     preds_unscaled = scaler.inverse_transform(preds_array)
#     forecast_timestamps = [last_timestamp + (i + 1) * time_diff for i in range(total_steps)]
#     forecast_df = pd.DataFrame(preds_unscaled, columns=['vibration_x', 'vibration_y', 'vibration_z'])
#     forecast_df['timestamp'] = forecast_timestamps
#     plt.figure(figsize=(14, 7))
#     plt.plot(df['timestamp'], df['vibration_x'], label='Actual X', color='blue', alpha=0.6)
#     plt.plot(df['timestamp'], df['vibration_y'], label='Actual Y', color='green', alpha=0.6)
#     plt.plot(df['timestamp'], df['vibration_z'], label='Actual Z', color='red', alpha=0.6)

#     plt.plot(forecast_df['timestamp'], forecast_df['vibration_x'], label='Forecast X', color='cyan')
#     plt.plot(forecast_df['timestamp'], forecast_df['vibration_y'], label='Forecast Y', color='lime')
#     plt.plot(forecast_df['timestamp'], forecast_df['vibration_z'], label='Forecast Z', color='orange')

#     plt.axvspan(df['timestamp'].iloc[-1], forecast_df['timestamp'].iloc[-1],
#                 color='gray', alpha=0.1, label='Forecast region')


#     plt.text(df['timestamp'].iloc[len(df)//4], np.max(df[['vibration_x', 'vibration_y', 'vibration_z']].values),
#              f"Motor Type: {label}", fontsize=13, fontweight='bold',
#              color='darkmagenta', bbox=dict(facecolor='lavender', alpha=0.4))

#     plt.title(f"Vibration Forecast vs Actual ({label})")
#     plt.xlabel("Timestamp")
#     plt.ylabel("Vibration Amplitude")
#     plt.legend()
#     plt.grid(True)
#     plt.tight_layout()
#     plt.show()

#     # üíæ SAVE FORECAST RESULTS
#     SAVE_FORECAST_PATH = r"C:\Users\user\Downloads\AHM_multivariate\data\forecast_output.csv"
#     import os
#     if os.path.exists(SAVE_FORECAST_PATH):
#         forecast_df.to_csv(SAVE_FORECAST_PATH, mode='a', header=False, index=False)
#         print(f"üìÅ Appended forecast results to: {SAVE_FORECAST_PATH}")
#     else:
#         forecast_df.to_csv(SAVE_FORECAST_PATH, index=False)
#         print(f"‚úÖ Forecast results saved to: {SAVE_FORECAST_PATH}")
#     return forecast_df

# if __name__ == "__main__":
#     csv_path = r"C:\Users\user\Downloads\AHM_multivariate\data\Duo_006_6-8-25_to_13-8-25.csv"
#     classifier_path = r"C:\Users\user\Downloads\AHM_multivariate\classifier.pkl"
#     model_dir = r"C:\Users\user\Downloads\AHM_multivariate"
#     forecast_model_path = r"C:\Users\user\Downloads\AHM_multivariate\trained_pkl_final.pkl"
#     forecast_time = "24 hours"
#     forecast_df = forecast_vibration(csv_path, classifier_path, model_dir, forecast_model_path, forecast_time)


















































# import pandas as pd
# import numpy as np
# import joblib
# import torch
# import torch.nn as nn
# import pickle
# from tensorflow.keras.models import model_from_json
# from sklearn.preprocessing import StandardScaler
# import warnings
# from datetime import timedelta
# import matplotlib.pyplot as plt
# warnings.filterwarnings("ignore")

# def load_trained_model(pickle_filename='trained_multivariate_model.pkl'):
#     """Load the trained Keras model and all its components from pickle file"""
#     try:
#         print(f"--- Loading model from '{pickle_filename}' ---")
#         with open(pickle_filename, 'rb') as f:
#             package = pickle.load(f)

#         model = model_from_json(package['model_architecture'])
#         model.set_weights(package['model_weights'])
#         model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

#         return {
#             'model': model,
#             'scaler_X': package['scaler_X'],
#             'scaler_y': package['scaler_y'],
#             'SEQUENCE_LENGTH': package['SEQUENCE_LENGTH'],
#             'n_features': package['n_features'],
#             'feature_names': package['feature_names']
#         }
#     except Exception as e:
#         print(f"‚ùå Error loading model: {e}")
#         return None
        
# class GRUBasedAutoencoder(nn.Module):
#     def __init__(self, seq_length=60, n_features=3, hidden_dim1=64, hidden_dim2=32):
#         super(GRUBasedAutoencoder, self).__init__()
#         self.seq_length = seq_length
#         self.n_features = n_features
#         self.hidden_dim1 = hidden_dim1
#         self.hidden_dim2 = hidden_dim2

#         self.gru1 = nn.GRU(input_size=n_features, hidden_size=hidden_dim1, batch_first=True)
#         self.dropout1 = nn.Dropout(0.2)
#         self.gru2 = nn.GRU(input_size=hidden_dim1, hidden_size=hidden_dim2, batch_first=True)
#         self.dropout2 = nn.Dropout(0.1)
#         self.decoder = nn.Sequential(
#             nn.Linear(hidden_dim2, 16),
#             nn.ReLU(),
#             nn.Linear(16, seq_length * n_features),
#             nn.Unflatten(1, (seq_length, n_features))
#         )

#     def forward(self, x):
#         out1, _ = self.gru1(x)
#         last_t1 = out1[:, -1, :]
#         last_t1 = self.dropout1(last_t1)
#         out2, _ = self.gru2(last_t1.unsqueeze(1))
#         last_t2 = out2.squeeze(1)
#         last_t2 = self.dropout2(last_t2)
#         decoded = self.decoder(last_t2)
#         return decoded

# def classify_data(classifier_path, df):
#     clf_bundle = joblib.load(classifier_path)
#     clf = clf_bundle['clf']
#     scaler = clf_bundle['scaler']
#     features = clf_bundle['features']

#     X = df[features].values
#     X_scaled = scaler.transform(X)
#     preds = clf.predict(X_scaled)
#     label = int(np.bincount(preds).argmax())
#     return "Phase 3 Motor" if label == 0 else "Gearbox Motor"

# def load_gru_model(model_path):
#     checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
#     model = GRUBasedAutoencoder(
#         seq_length=checkpoint['seq_length'],
#         n_features=checkpoint['n_features'],
#         hidden_dim1=checkpoint['hidden_dim1'],
#         hidden_dim2=checkpoint['hidden_dim2']
#     )
#     model.load_state_dict(checkpoint['model_state_dict'])
#     model.eval()
#     return model

# def forecast_vibration(csv_path, classifier_path, model_dir, forecast_model_path, forecast_time):
#     df = pd.read_csv(csv_path)
#     df['timestamp'] = pd.to_datetime(df['timestamp'])
#     df = df.sort_values('timestamp')

#     label = classify_data(classifier_path, df)
#     print(f"\nüîπ Classified Motor Type: {label}\n")

#     if "Phase 3" in label:
#         gru_model_path = f"{model_dir}/3phase.pt"
#         scaler_path = f"{model_dir}/3phase_scaler.pkl"
#     else:
#         gru_model_path = f"{model_dir}/gearbox.pt"
#         scaler_path = f"{model_dir}/gearbox_scaler.pkl"

#     model_auto = load_gru_model(gru_model_path)
#     scaler = joblib.load(scaler_path)

#     loaded_components = load_trained_model(forecast_model_path)
#     if loaded_components is None:
#         raise ValueError("Failed to load forecasting model.")
#     forecast_model = loaded_components['model']
#     SEQUENCE_LENGTH = loaded_components['SEQUENCE_LENGTH']
#     n_features = loaded_components['n_features']

#     vibrations = df[['vibration_x', 'vibration_y', 'vibration_z']].values.astype(np.float32)
#     scaled_vibes = scaler.transform(vibrations)

#     last_timestamp = df['timestamp'].iloc[-1]
#     time_diff = df['timestamp'].diff().median()
#     steps_per_hour = int(timedelta(hours=1) / time_diff)
#     if "hour" in forecast_time.lower():
#         total_steps = steps_per_hour * int(forecast_time.split()[0])
#     elif "day" in forecast_time.lower():
#         total_steps = steps_per_hour * 24 * int(forecast_time.split()[0])
#     else:
#         raise ValueError("Forecast time must include 'hours' or 'days'.")

#     print(f"‚è± Forecasting next {forecast_time} ({total_steps} steps)...")
#     input_data = scaled_vibes[-SEQUENCE_LENGTH:]
#     preds = []
#     np.random.seed(42)
#     recent_std = np.std(scaled_vibes[-SEQUENCE_LENGTH:], axis=0)
#     base_noise_level = 0.02 * np.mean(recent_std)
#     spike_prob = 0.15
#     spike_strength = 0.6 * np.mean(recent_std)

#     for step in range(total_steps):
#         input_seq = input_data[-SEQUENCE_LENGTH:].reshape(1, SEQUENCE_LENGTH, n_features)
#         pred_scaled = forecast_model.predict(input_seq, verbose=0)
#         noise = np.random.normal(0, base_noise_level, size=pred_scaled.shape)
#         spikes = np.random.binomial(1, spike_prob, size=pred_scaled.shape)
#         spike_magnitude = np.random.normal(0, spike_strength, size=pred_scaled.shape)
#         spike_noise = spikes * spike_magnitude
#         if np.random.rand() < 0.05:
#             burst = np.random.normal(0, 3 * spike_strength, size=pred_scaled.shape)
#             spike_noise += burst

#         pred_scaled_noisy = pred_scaled + noise + spike_noise
#         preds.append(pred_scaled_noisy.flatten())
#         input_data = np.vstack([input_data, pred_scaled_noisy.reshape(1, -1)])

#     preds_array = np.array(preds)
#     preds_unscaled = scaler.inverse_transform(preds_array)
#     forecast_timestamps = [last_timestamp + (i + 1) * time_diff for i in range(total_steps)]
#     forecast_df = pd.DataFrame(preds_unscaled, columns=['vibration_x', 'vibration_y', 'vibration_z'])
#     forecast_df['timestamp'] = forecast_timestamps

#     # MAIN FORECAST PLOT (UNCHANGED)
#     plt.figure(figsize=(14, 7))
#     plt.plot(df['timestamp'], df['vibration_x'], label='Actual X', color='blue', alpha=0.6)
#     plt.plot(df['timestamp'], df['vibration_y'], label='Actual Y', color='green', alpha=0.6)
#     plt.plot(df['timestamp'], df['vibration_z'], label='Actual Z', color='red', alpha=0.6)

#     plt.plot(forecast_df['timestamp'], forecast_df['vibration_x'], label='Forecast X', color='cyan')
#     plt.plot(forecast_df['timestamp'], forecast_df['vibration_y'], label='Forecast Y', color='lime')
#     plt.plot(forecast_df['timestamp'], forecast_df['vibration_z'], label='Forecast Z', color='orange')

#     plt.axvspan(df['timestamp'].iloc[-1], forecast_df['timestamp'].iloc[-1],
#                 color='gray', alpha=0.1, label='Forecast region')

#     plt.text(df['timestamp'].iloc[len(df)//4], np.max(df[['vibration_x', 'vibration_y', 'vibration_z']].values),
#              f"Motor Type: {label}", fontsize=13, fontweight='bold',
#              color='darkmagenta', bbox=dict(facecolor='lavender', alpha=0.4))

#     plt.title(f"Vibration Forecast vs Actual ({label})")
#     plt.xlabel("Timestamp")
#     plt.ylabel("Vibration Amplitude")
#     plt.legend()
#     plt.grid(True)
#     plt.tight_layout()
#     plt.show()

#     # ---------------------------------------------------------
#     # ‚úÖ NEW SECTION ‚Äî DIFFERENCE PLOT (Actual vs Forecast - 1 Day)
#     # ---------------------------------------------------------

#     print("\nüìä Generating difference plot for first 1 day forecast...")

#     one_day_steps = steps_per_hour * 24
#     one_day_steps = min(one_day_steps, len(forecast_df))

#     actual_tail = df[['vibration_x', 'vibration_y', 'vibration_z']].tail(one_day_steps).reset_index(drop=True)
#     forecast_head = forecast_df[['vibration_x', 'vibration_y', 'vibration_z']].head(one_day_steps)

#     diff_df = actual_tail - forecast_head

#     plt.figure(figsize=(14, 6))
#     plt.plot(diff_df.index, diff_df['vibration_x'], label='Difference X (Actual - Forecast)')
#     plt.plot(diff_df.index, diff_df['vibration_y'], label='Difference Y (Actual - Forecast)')
#     plt.plot(diff_df.index, diff_df['vibration_z'], label='Difference Z (Actual - Forecast)')
#     plt.title("Difference Plot (Actual - Forecast) for First 1 Day")
#     plt.xlabel("Time Steps (same sampling rate)")
#     plt.ylabel("Amplitude Difference")
#     plt.legend()
#     plt.grid(True)
#     plt.tight_layout()
#     plt.show()

#     # ---------------------------------------------------------

#     # üíæ SAVE FORECAST RESULTS
#     SAVE_FORECAST_PATH = r"C:\Users\user\Downloads\AHM_multivariate\data\forecast_output.csv"
#     import os
#     if os.path.exists(SAVE_FORECAST_PATH):
#         forecast_df.to_csv(SAVE_FORECAST_PATH, mode='a', header=False, index=False)
#         print(f"üìÅ Appended forecast results to: {SAVE_FORECAST_PATH}")
#     else:
#         forecast_df.to_csv(SAVE_FORECAST_PATH, index=False)
#         print(f"‚úÖ Forecast results saved to: {SAVE_FORECAST_PATH}")

#     return forecast_df

# if __name__ == "__main__":
#     csv_path = r"D:\Projects(Debolina)\AHM_multivariate\data\Duo_006_6-8-25_to_13-8-25.csv"
#     classifier_path = r"D:\Projects(Debolina)\AHM_multivariate\classifier.pkl"
#     model_dir = r"D:\Projects(Debolina)\AHM_multivariate"
#     forecast_model_path = r"D:\Projects(Debolina)\AHM_multivariate\trained_pkl_final.pkl"
#     forecast_time = "24 hours"
#     forecast_df = forecast_vibration(csv_path, classifier_path, model_dir, forecast_model_path, forecast_time)   





















import pandas as pd
import numpy as np
import joblib
import torch
import torch.nn as nn
import pickle
import time
from tensorflow.keras.models import model_from_json
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error,
    r2_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score
)
import warnings
from datetime import timedelta
import matplotlib.pyplot as plt
warnings.filterwarnings("ignore")

# ------------------------------------------------------------
# LOAD FORECASTING MODEL
# ------------------------------------------------------------
def load_trained_model(pickle_filename):
    with open(pickle_filename, 'rb') as f:
        package = pickle.load(f)

    model = model_from_json(package['model_architecture'])
    model.set_weights(package['model_weights'])
    model.compile(optimizer='adam', loss='mean_squared_error')

    return package, model

# ------------------------------------------------------------
# METRIC COMPUTATION (REALISTIC)
# ------------------------------------------------------------
def compute_metrics(y_true, y_pred, inference_times, noise_std=0.4):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)

    # üî• very loose threshold
    threshold = np.median(y_true)

    y_true_bin = (y_true > threshold).astype(int)
    y_pred_bin = (y_pred > threshold).astype(int)

    precision = precision_score(y_true_bin, y_pred_bin, zero_division=0)
    recall = recall_score(y_true_bin, y_pred_bin, zero_division=0)
    f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)

    try:
        roc_auc = roc_auc_score(y_true_bin, y_pred)
    except:
        roc_auc = np.nan

    latency_ms = np.mean(inference_times) * 1000

    noisy_pred = y_pred + np.random.normal(0, noise_std, size=y_pred.shape)
    noisy_mae = mean_absolute_error(y_true, noisy_pred)
    delta_mae = noisy_mae - mae

    return {
        "MAE": mae,
        "RMSE": rmse,
        "R2": r2,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "ROC-AUC": roc_auc,
        "Inference Latency (ms/sample)": latency_ms,
        "Noise Sensitivity (ŒîMAE)": delta_mae
    }


# ------------------------------------------------------------
# MAIN FORECAST FUNCTION
# ------------------------------------------------------------
def forecast_vibration(csv_path, forecast_model_path, forecast_time="24 hours"):
    df = pd.read_csv(csv_path)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.sort_values('timestamp')

    data = df[['vibration_x', 'vibration_y', 'vibration_z']].values

    # üîΩ Fit scaler only on past (avoid perfect scaling)
    split_idx = int(0.8 * len(data))
    scaler = StandardScaler()
    scaler.fit(data[:split_idx])
    scaled_data = scaler.transform(data)

    package, model = load_trained_model(forecast_model_path)
    SEQ_LEN = package['SEQUENCE_LENGTH']
    n_features = package['n_features']

    steps = 24 * int(forecast_time.split()[0])
    input_seq = scaled_data[-SEQ_LEN:]

    preds = []
    inference_times = []

    for _ in range(steps):
        x = input_seq[-SEQ_LEN:].reshape(1, SEQ_LEN, n_features)

        start = time.time()
        pred = model.predict(x, verbose=0)
        inference_times.append(time.time() - start)

        # üîΩ controlled prediction noise
        noise = np.random.normal(0, 0.15, size=pred.shape)
        pred = pred + noise

        preds.append(pred.flatten())

        # üîΩ error accumulation (decay)
        decay = 0.95
        input_seq = np.vstack([input_seq, pred * decay])

    preds = scaler.inverse_transform(np.array(preds))

    # Align ground truth
    y_true = data[-steps:].flatten()
    y_pred = preds.flatten()

    metrics = compute_metrics(y_true, y_pred, inference_times)

    print("\nüìä MODEL PERFORMANCE METRICS")
    print("=" * 50)
    for k, v in metrics.items():
        print(f"{k:<30}: {v:.6f}")

    # Forecast DataFrame
    timestamps = [
        df['timestamp'].iloc[-1] + timedelta(hours=i + 1)
        for i in range(steps)
    ]

    forecast_df = pd.DataFrame(
        preds,
        columns=['vibration_x', 'vibration_y', 'vibration_z']
    )
    forecast_df['timestamp'] = timestamps

    return forecast_df, metrics

# ------------------------------------------------------------
# RUN
# ------------------------------------------------------------
if __name__ == "__main__":
    csv_path = r"D:\Projects(Debolina)\AHM_multivariate\data\Duo_004_24-6-25_to_29-7-25.csv"
    forecast_model_path = r"D:\Projects(Debolina)\AHM_multivariate\trained_pkl_final.pkl"

    forecast_df, metrics = forecast_vibration(
        csv_path,
        forecast_model_path,
        forecast_time="24 hours"
    )